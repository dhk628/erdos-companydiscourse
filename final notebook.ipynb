{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Discourse\n",
    "\n",
    "### **Finding Numerical Ratings of Consumer Sentiments using GTE Sentence Trasformer**\n",
    "\n",
    "by Vinicius Ambrosi, Gilyoung Cheong, Dohoon Kim, Hannah Lloyd\n",
    "\n",
    "**Abstract**. There is a wealth of discourse on companies and their products on social media platforms and online forums. While many approaches leverage analytical techniques to gauge audience sentiment through online discourse, they lack the ability to be both targeted and customizable while maintaining complex analytical integrity. We used Sentence Trasformer, the state-of-art text embedding API, with GTE (General Text Embeddings with Multi-stage Contrastive Learning) pretrained model, to vectorize 792,021 comments from Google Reviews into a 1024-dimensional vector space. We then used these vectors as features to train our models and develop rating models that rate a given comment from 1 to 5 stars. Each vector provides 1024 features for a review comment, with the target variable being the rating. We developed our models using Logistic Regression (One vs. Rest), k-Nearest Neigbor, XGBoost, and a Feedforward Neural Network with 30 hidden layers using ReLU activation after appropriate train-test splits. To address the biased nature of the training data, which favors 4 or 5-star ratings, we significantly improved our models by random under-sampling. To corroborate the performance of our models, we test them on another review dataset unrelated to Google Reviews for the same business. Our experiemental results provide how to use pre-trained Sentence Transformer to extract numerical values of consumer sentiments from online comments without extra cost of pre-training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S1.$ Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online comments and reviews have grown increasingly vital in shaping consumer decisions, particularly in the aftermath of the COVID-19 pandemic. Numerous studies, including those by [[1]](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2022.865702/full), [[3]](https://link.springer.com/chapter/10.1007/978-981-19-5443-6_1), [[8]](https://ieeexplore.ieee.org/document/8970492), [[9]](https://www.sciencedirect.com/science/article/pii/S0747563210000907), [[10]](https://ieeexplore.ieee.org/document/8631160), and [[11]](https://www.sciencedirect.com/science/article/abs/pii/S1567422320300570) have underscored the significance of analyzing consumer sentiments within the realms of e-commerce and tourism. The importance of these sentiments has been highlighted, showing that understanding consumer feedback can provide valuable insights into market trends and customer preferences. In light of these findings, this report utilizes Natural Language Processing (NLP) and Machine Learning (ML) techniques to construct predictive models capable of assessing and rating comments provided by consumers. By employing these advanced analytical methods, we aim to enhance the accuracy and effectiveness of sentiment analysis in understanding and forecasting consumer behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1. NLP Methodology: GTE Sentence Transformer**. We use Sentence Transformer, the state-of-the-art text embedding NLP, to vectorize 792,021 pre-processed comments from Google Reviews about a specific business (Costco). These vectors then serve as input features for building predictive models for ratings. The pretrained model for our sentence transformer is GTE (General Text Embeddings with Multi-stage Contrastive Learning) developed by Alibaba Group NLP team in [[5]](https://arxiv.org/abs/2308.03281). The earliest Sentence Transfomer (Sentence-BERT) was was developed as outlined in [[6]](https://arxiv.org/abs/1908.10084) by Reimers and Gurebych and is based on BERT, which stands for Bidirectional Encoder Representations from Transformers, introduced in [[2]](https://arxiv.org/abs/1810.04805) by Google.\n",
    "\n",
    "BERT was revolutionary because it provided vector representations of sentences, with each subword token encoded into a vector that retains its relationship with the entire input context. This contextual awareness enabled BERT to excel in tasks such as question answering, where it generates answers based on user-provided context. \n",
    "\n",
    "However, using BERT for sentence clustering posed challenges because it required providing the full context every time a sentence was vectorized. This limitation made BERT less suitable for building predictive models that need to be tested on unknown data. Additionally, since BERT encodes each subword of a sentence into a vector, a sentence corresponds to a sequence of vectors, not a single vector, which requires significant storage. Various attempts to address these issues involved encoding each sentence without context and using either the encoded vector of the first special token (called the [CLS] token) or the average vector of the sequence of encoded vectors of all subwords, but these approaches led to poor performance.\n",
    "\n",
    "Sentence Transformers use specific loss functions to train the average BERT-generated vector of subwords of each sentence in the training set so that two semantically similar sentences are associated with two vectors that are close to each other in terms of (Euclidean) distance and angle. The details of the pre-training and fine-tuning processes of GTE Sentence Transformer are available in Section 3 of [[5]](https://arxiv.org/abs/2308.03281)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2. ML Methodology: Logistic Regression, kNN, XGBoost, and FNN**. We use several widely accessible Machine Learning (ML) models to train on the vectors we get from GTE Sentence Transformer on our data so that they can rate a given online comment from 1 to 5 stars to capture consumers' sentiments. Specifically, we use Logistic Regression, k-Nearest Neighbor (kNN), XGBoost, and Feedforward Neural Network (FNN) to build our models.\n",
    "\n",
    "**1.3. Data and Variables**. We use [2021 Google Review data](https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/googlelocal/) collected by Li and Zhang for their papers [[4]](https://aclanthology.org/2022.acl-long.426.pdf) and [[7]](https://dl.acm.org/doi/abs/10.1145/3539618.3592036). During our pre-processing, using the Google Maps ID attached to each data point, we extracted 792,021 reviews for Costco from consumers in the United States. We use GTE Sentence Transformer to construct a unique vector for each review comment in $\\mathbb{R}^{1024}$, the real vector space of dimension 1024. Each component of such a vector is used as an input feature for each comment, so a comment gets 1024 input features. The target variable is rating, which is an integer in $\\{1, 2, 3, 4, 5\\}$. The following is the scatter plot of our training set, which is 80% of our data, projected on the first and second principal components:\n",
    "\n",
    "<center>\n",
    "<img src=\"PCA picture.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "For building our models, we first separate training set with test set with the ratio of 8:2. Within the training set, we apply 11-fold cross validation for each ML method when we build our models.\n",
    "\n",
    "**1.4. Key Contribution**. Our key contribution is to showcase how the imblanced nature of our data influence to various accssible ML models we use in predictive analysis for consumer sentiments when it comes to online reviews. Focusing on the accurcy alone is misleading because our data is highly imbalanced. The following is the histogram for ratings in our testing set:\n",
    "\n",
    "<center>\n",
    "<img src=\"Imbalance picture.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Thus, for each predictive modeling, we also build additional model after random-under sampling. The overall accuracy drops, but the confusion matrix is much more convincing.\n",
    "\n",
    "**1.5. Comparing with Preceding Works**. There are have been great interests in analyzing consumers' sentiment, many of which are surveyed by Yang, Li, Wang, and Sherratt in Section II of [[8]](https://ieeexplore.ieee.org/document/8970492). In Section III of their paper, the authors also devleop their own sentiment analysis model by manually identifying (sub)words with positive and negative sentiments to create weights attached to BERT-generated vectors from the comments they pre-train. Then they apply Convolutional Neural Network (CNN) get and a modified version of Recurrent Neural Network (RNN) to modify vectors so that they are ideally infludenced by a few words with stong sentiment and remember relationship between words. After that they apply another linear later with hyperbolic tangent activation followed by SoftMax to get a numerical value between 0 and 1. Then the authors of [[8]](https://ieeexplore.ieee.org/document/8970492) use a real-world data set with rating to be able to compare their model with the true rating. Their classification is binary by classifying 1 and 2 starts to be positive while 3, 4, and 5 stars to be negative. On the other hand, our approach is greatly simplified thanks to Sentence Transformer, which cuts the pre-training step, which can be significant reduction in cost for deployment. \n",
    "\n",
    "In [[3]](https://link.springer.com/chapter/10.1007/978-981-19-5443-6_1), Kim, Lee, Lim, Kim, and Hong also used Senternce Transformer can be found in  by ranking top tourist spots in Busan, South Korea, by measureing cosine similairties between a vector generated by the given query sentence (e.g., \"It is a beautiful beach\") to the vectors generated from online review comments. Two major differences are that\n",
    "\n",
    "1. Kim et al used the model [\"all-MiniLM-L6-v2\"](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) for the sentence transformer, while we use GTE: [\"thenlper/gte-large\"](https://huggingface.co/thenlper/gte-large);\n",
    "2. the input features for Kim et al are generated by the cosine similarities between the comment vectors and a given query vector, while we directly use components of the comment vectors as our input features so that no information is possibly lost after vectorization.\n",
    "\n",
    "In either wrok above, the issue for the imbalance in data is not addressed. Overall, dealing with the imbalanced issue with consumer sentiment analysis is not much addressed in the literature when it comes to consumer sentiment analysis, despite it being a common issue in Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### $\\S2.$ Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Logistic regression.** When we apply logistic regression on the original training data, we get, as the average of the 11-fold cross-validation, the following results:\n",
    "\n",
    "Accuracy: 0.7410\n",
    "\n",
    "Cross Entropy: 0.6575\n",
    "\n",
    "Confusion Matrix:\n",
    "<center>\n",
    "<img src=\"Images/LogisticRegression_ovr_liblinear_NoneType.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Note that here and henceforth, our confusion matrices are normalized across the rows, i.e. the true labels.\n",
    "\n",
    "On the other hand, after randomly undersampling all the non-minority classes, we get:\n",
    "\n",
    "Accuracy: 0.6495\n",
    "\n",
    "Cross Entropy: 0.9113\n",
    "\n",
    "Confusion Matrix:\n",
    "<center>\n",
    "<img src=\"Images/LogisticRegression_ovr_liblinear_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "As discussed in Section 1.4, undersampling the data reduces the accuracy, but yields a confusion matrix that has higher values near the diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Random oversampler.** If we initially apply a random oversample to the minority classes to a size of 30000, then randomly undersample the majority classes to 30000, we get:\n",
    "\n",
    "Accuracy: 0.6496\n",
    "\n",
    "Cross Entropy: 0.9039\n",
    "\n",
    "Confusion Matrix:\n",
    "<center>\n",
    "<img src=\"Images/LogisticRegression_ovr_liblinear_RandomOverSampler_30k_RandomUnderSampler_30k.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "This approach has no meaninful diffence to only undersampling, and indeed, adding shrinkage to the random oversampler yielded similar results. On the other hand, most other oversamplers and undersamplers provided in the `imblearn` package has a high computational cost for our data. One solution is to apply principal component analysis to reduce the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Principal component analysis.** In this section, we will analyze the effect of applying principal component analysis (PCA) to the data before randomly undersampling and then applying logistic regression. When we apply PCA to 128 dimensions, we get:\n",
    "\n",
    "Accuracy: 0.6492\n",
    "\n",
    "Cross Entropy: 0.9213\n",
    "\n",
    "Confusion Matrix:\n",
    "<center>\n",
    "<img src=\"Images/LogisticRegression_ovr_liblinear_PCA128_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "If we train the model on the first 64 principal components, we get\n",
    "\n",
    "Accuracy: 0.6467\n",
    "\n",
    "Cross Entropy: 0.9291\n",
    "\n",
    "Confusion Matrix:\n",
    "<center>\n",
    "<img src=\"Images/LogisticRegression_ovr_liblinear_PCA64_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "When we use only the first 8 principal components, we get\n",
    "\n",
    "Accuracy: 0.6345\n",
    "\n",
    "Cross Entropy: 0.9642\n",
    "\n",
    "Confusion Matrix:\n",
    "<center>\n",
    "<img src=\"Images/LogisticRegression_ovr_liblinear_PCA8_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "As expected, the performance does decrease as we use less principal components. On the other hand, the results are still quite reasonable, which indicates that PCA onto the above dimensions do not lead to a severe loss of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Other balancing methods.** We will analyze the effect of applying more computationally expensive balancing methods after using PCA.\n",
    "\n",
    "Using the first 8 principal components, if we apply Synthetic Minority Over-sampling Technique (SMOTE) to oversample the minority classes to 100000 and then randomly undersample the majority classes to 100000, applying logistic regression gives:\n",
    "\n",
    "Accuracy: 0.6339\n",
    "\n",
    "Cross Entropy: 0.9561\n",
    "\n",
    "Confusion Matrix:\n",
    "<center>\n",
    "<img src=\"Images/LogisticRegression_ovr_liblinear_PCA8_SMOTE_100k_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Applying SMOTE does not seem to affect the performance in a meaningful way. Other undersampling methods, such as Cluster Centroids or Edited Nearest Neighbors, took quite long to complete even when only using 8 principal components, so henceforth, we will focus on the random undersampler. However, these other methods should be explored in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S3.$ K-Nearest Neighbors\n",
    "\n",
    "Applying k-nearest neighbors (KNN) to the original dataset is computationally expensive, so we will make use of PCA.\n",
    "\n",
    "Using the first 16 principal components, if we apply KNN with 50 neighbors without balancing the data, we get: \n",
    "\n",
    "Accuracy: 0.7346\n",
    "\n",
    "Cross Entropy: 0.8503\n",
    "\n",
    "Confusion Matrix:\n",
    "<center>\n",
    "<img src=\"Images/KNeighborsClassifier_n50_PCA16_NoneType.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "The performance is worse than logistic regression.\n",
    "\n",
    "Using the first 16 principal components, if we apply KNN with 50 neighbors after randomly undersampling the non-minority classes, we get:\n",
    "\n",
    "Accuracy: 0.6054\n",
    "\n",
    "Cross Entropy: 1.2434\n",
    "\n",
    "Confusion Matrix:\n",
    "<center>\n",
    "<img src=\"Images/KNeighborsClassifier_n50_PCA16_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Again, the performance is worse than logistic regression. Furthermore, we can see the same pattern where undersampling the data lowers the accuracy but gives a more reasonable confusion matrix.\n",
    "\n",
    "Using the first 128 principal components, if we apply KNN with 200 neighbors after randomly undersampling the non-minority classes, we get:\n",
    "\n",
    "Accuracy: 0.6298\n",
    "\n",
    "Cross Entropy: 0.9751\n",
    "\n",
    "Confusion Matrix:\n",
    "<center>\n",
    "<img src=\"Images/KNeighborsClassifier_n200_PCA128_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Increasing the number of principal components and the number of neighbors, at least up to 200, seems to the accuracy at the cost of computation time. These hyperparameters have not been fully explored, but these results indicate that logistic regression has comparable performance to KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S4.$ Support Vector Classification\n",
    "\n",
    "Support vector classification (SVC) is also computationally expensive, so we will employ PCA here as well.\n",
    "\n",
    "Using the first 128 principal components, applying SVC after randomly undersampling gives:\n",
    "\n",
    "Accuracy: 0.6391\n",
    "\n",
    "Cross Entropy: 0.8844\n",
    "\n",
    "Confusion Matrix:\n",
    "<center>\n",
    "<img src=\"Images/SVC_PCA128_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S5.$ XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S6.$ Feedforard Neural Network (FNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply FNN with 30 hidden layers with ReLU activation of the following form:\n",
    "\n",
    "$$\\mathbb{R}^{1024} \\rightarrow \\mathbb{R}^{6} \\rightarrow \\mathbb{R}^{6} \\rightarrow \\cdots \\rightarrow \\mathbb{R}^{6} \\rightarrow \\mathbb{R}^{5}.$$\n",
    "\n",
    "We use cross entropy as loss function. For each fold of 11-folds, we run two epochs with batch size 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without random undersampling, we get\n",
    "\n",
    "**Accuracy**: 0.7403\n",
    "\n",
    "**Cross Entropy**: 0.6615\n",
    "\n",
    "**Confusion Matrix**:\n",
    "<center>\n",
    "<img src=\"neural_network_cm_before_undersampling.png\" width=\"50%\"></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "<a id=\"1\">[1]</a> \n",
    "T. Chen, P. Samaranayake, X. Cen, M. Qi, and Y. Lan. (2022). \"**The Impact of Online Reviews on Consumers’ Purchasing Decisions: Evidence From an Eye-Tracking Study**,\" Front Psychol. **13**: 865702.\n",
    "\n",
    "<a id=\"1\">[2]</a> \n",
    "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019). \"**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**,\" Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\n",
    "\n",
    "<a id=\"1\">[3]</a> \n",
    "M. S. Kim, K. W. Lee, J. W. Lim, D. H. Kim, and S. Hong. (2023). \"**Ranking Roughly Tourist Destinations Using BERT-Based Semantic Search**\", Shakya, S., Du, KL., Ntalianis, K. (eds) Sentiment Analysis and Deep Learning. Advances in Intelligent Systems and Computing, vol 1432. Springer, Singapore.\n",
    "\n",
    "<a id=\"1\">[4]</a>\n",
    "Jiacheng Li, Jingbo Shang, and Julian McAuley. (2022). \"**UCTopic: Unsupervised Contrastive Learning for Phrase Representations and Topic Mining**,\" Annual Meeting of the Association for Computational Linguistics (ACL)\n",
    "\n",
    "<a id=\"1\">[5]</a>\n",
    "Z. Li, X. Zhang, Y. Zhang, D. Long, P. Xie, and M. Zhang. (2023).\"**Towards General Text Embeddings with Multi-stage Contrastive Learning**,\" arXiv preprint: https://arxiv.org/abs/2308.03281\n",
    "\n",
    "<a id=\"1\">[6]</a>\n",
    "N. Reimers and I. Gurebych. (2019). \"**Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks**,\" Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, p.3982–3992, Hong Kong, China, November 3–7, 2019.\n",
    "\n",
    "<a id=\"1\">[7]</a>\n",
    "An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, and Julian Mcauley. (2023). \"**Personalized Showcases: Generating Multi-Modal Explanations for Recommendations**,\"The 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)\n",
    "\n",
    "<a id=\"1\">[8]</a>\n",
    "L. Yang, Y. Li, J. Wang, and R. S. Sherratt. (2020). \"**Sentiment Analysis for E-Commerce Product Reviews in Chinese Based on Sentiment Lexicon and Deep Learning**,\" IEEE Access **8**: p.23522-23530.\n",
    "\n",
    "<a id=\"1\">[9]</a>\n",
    "Qiang Ye, R. Law, B. Gu, and W. Chen. (2011). \"**The influence of user-generated content on traveler behavior: An empirical investigation on the effects of e-word-of-mouth to hotel online bookings**,\"  Computers in Human Behavior **2**: p.634-639.\n",
    "\n",
    "<a id=\"1\">[10]</a>\n",
    "Zhang and Zhong. (2019). \"**Mining Users Trust From E-Commerce Reviews Based on Sentiment Similarity Analysis**,\" IEEE Access **7**: p.13523-13535.\n",
    "\n",
    "<a id=\"1\">[11]</a>\n",
    "Y. Zhao, L. Wang, H. Tang, and Y. Zhang. (2020). \"**Electronic word-of-mouth and consumer purchase intentions in social e-commerce**,\" Electronic Commerce Research and Applications, **41**: 100980."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
