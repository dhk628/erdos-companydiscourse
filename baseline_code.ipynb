{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Discourse\n",
    "\n",
    "### 1. Dependencies (i.e., libraries we use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw # https://praw.readthedocs.io/ -- PRAW for scraping Reddit comments\n",
    "from praw.models import MoreComments\n",
    "\n",
    "from sentence_transformers import SentenceTransformer # https://sbert.net/ -- SBERT for sentence comparison\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm, tqdm_notebook # https://tqdm.github.io/ -- measures runtime of loops\n",
    "from datetime import datetime # https://docs.python.org/3/library/datetime.html -- to manipulate time units\n",
    "import os.path # https://docs.python.org/3/library/os.path.html -- this lets us tell whether to load or create/save dataframe\n",
    "\n",
    "from credentials import reddit_credential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Functions for Scraping Reddit Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit account info to use PRAW\n",
    "# We should find some way to hide this part of the code eventually (quasi-personal info)\n",
    "reddit = praw.Reddit(\n",
    "    client_id=reddit_credential[\"client_id\"],\n",
    "    client_secret=reddit_credential[\"client_secret\"],\n",
    "    password=reddit_credential[\"password\"],\n",
    "    user_agent=reddit_credential[\"user_agent\"],\n",
    "    username=reddit_credential[\"username\"],\n",
    ")\n",
    "\n",
    "reddit.read_only = True # we are only going to read data, so let's keep it this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.comments consists of one of the following objects\n",
    "# Comment\n",
    "# MoreComments -- which may contain Comment objects or MoreComment objects\n",
    "# The following function break all MoreComments objects into Comment objects\n",
    "\n",
    "def break_into_comments(submission):\n",
    "    comment_like_objects = list(submission.comments)\n",
    "    folded_comments = []\n",
    "    saved_comments = []\n",
    "     # list() -- only needed to make it more concrete when we check the code\n",
    "    while comment_like_objects: # loop continues until comment_like_objects become empty\n",
    "        for comment in comment_like_objects:\n",
    "            if (isinstance(comment, MoreComments)):\n",
    "                folded_comments.append(comment)\n",
    "            else:\n",
    "                saved_comments.append(comment)\n",
    "        comment_like_objects = folded_comments # updating comment_like_objects\n",
    "        folded_comments = []\n",
    "\n",
    "    return saved_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: either submission or comment\n",
    "# output: time of the submission in local time as datetime object\n",
    "\n",
    "def time_of(submission):\n",
    "    ts = submission.created_utc # time given in unix timestamp\n",
    "    time = datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S') # This changes unix timestamp into local time\n",
    "    time = datetime.strptime(time, '%Y-%m-%d %H:%M:%S') # This changes into string datetime object\n",
    "\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: subreddit\n",
    "# output: comments from hot N submissions\n",
    "# within within [time_1, time_2] if time_1 and time_2 are typed in\n",
    "# time_1, time_2 are strings of the form '2024-05-09 23:10:02'\n",
    "# time_1 and time_2 only seem to work if it is within the day of the current time\n",
    "\n",
    "def extract_comments(subreddit, N, time_1=None, time_2=None):\n",
    "    saved_comments = []\n",
    "\n",
    "    if time_1 and time_2:\n",
    "        time_1 = datetime.strptime(time_1, '%Y-%m-%d %H:%M:%S')\n",
    "        time_2 = datetime.strptime(time_2, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        for submission in tqdm(subreddit.hot(limit=N)):\n",
    "            if time_1 <= time_of(submission) and time_of(submission) <= time_2:\n",
    "                saved_comments += break_into_comments(submission)\n",
    "    else:\n",
    "        for submission in subreddit.hot(limit=N):\n",
    "            saved_comments += break_into_comments(submission)\n",
    "\n",
    "    return saved_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Functions for Vectorizing Reddit Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining SBERT model for generating sentence embeddings\n",
    "sentence_model = SentenceTransformer(\"thenlper/gte-large\")\n",
    "\n",
    "# function that vectorizes a sentence\n",
    "def get_sentence_embedding(text):\n",
    "    if not text.strip():\n",
    "    #.strip() gets rid of new lines\n",
    "        print(\"Attempted to get embedding for empty text.\")\n",
    "        return []\n",
    "\n",
    "    embedding = sentence_model.encode(text)\n",
    "\n",
    "    return embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: comments\n",
    "# output: vectors in 1024-dim space corresponding to comments\n",
    "\n",
    "def comment_embeddings(comments):\n",
    "    embeddings = list(tqdm(map(get_sentence_embedding, [comment.body for comment in comments])))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Constructing and Saving/Loading Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas() # This would measure how much time we take whenever we use pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following generates df from comments\n",
    "# We need to add column for vectors later because generating them together takes forever\n",
    "\n",
    "def comments_into_df(comments):\n",
    "    dic = {\n",
    "            'Author' : [comment.author for comment in comments],\n",
    "            'Time (PDT)' : [time_of(comment) for comment in comments],\n",
    "            'Comment' : [comment.body for comment in comments],\n",
    "            'Vectors' : comment_embeddings(comments),\n",
    "            'File': comments\n",
    "            }\n",
    "\n",
    "    return pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: subreddit\n",
    "# output: dataframe from hot N submissions\n",
    "# within [time_1, time_2] if they are typed in\n",
    "# time_1, time_2 are strings of the form '2024-05-09 23:10:02'\n",
    "\n",
    "def extract_df(subreddit, N, time_1=None, time_2=None):\n",
    "    return comments_into_df(extract_comments(subreddit, N, time_1, time_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: subreddit_name (string)\n",
    "# execution: creates (and stores) or loads dataframes from hot N submissions of the given subreddit\n",
    "# within [time_1, time_2] if they are typed in\n",
    "# output: data_frame\n",
    "# time_1, time_2 are strings of the form '2024-05-09 23:10:02'\n",
    "# the name of the saved file: df_subreddit_name.csv\n",
    "\n",
    "def load_or_save_df(subreddit_name, N, time_1=None, time_2=None):\n",
    "\n",
    "    dataframe_name = 'df_' + subreddit_name + '.csv'\n",
    "    path = os.path.join('.', 'csvs', dataframe_name)\n",
    "\n",
    "    if os.path.exists(path): # if the file already exits in the directory, we just load it\n",
    "        df = pd.read_csv(path , converters={'Vectors': pd.eval})\n",
    "        # converters -- needed because otherwise vectors are loaded as str\n",
    "\n",
    "        df = df.drop(columns=\"Unnamed: 0\") # drop unwanted column that comes from read_csv\n",
    "    else:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        df = extract_df(subreddit, N, time_1, time_2)\n",
    "        df.to_csv(path) # save dataframe\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems to get a lot slower when as either time_2 - time_1 or N gets larger\n",
    "\n",
    "df_costco = load_or_save_df(\"Costco\", 50)\n",
    "df_mcdonalds = load_or_save_df(\"McDonalds\", 50)\n",
    "df_samsung = load_or_save_df(\"samsung\", 50)\n",
    "df_open_ai = load_or_save_df(\"OpenAI\", 50)\n",
    "\n",
    "# df_microsoft = load_or_save_df(\"microsoft\", N) -- Didn't stop for some reason\n",
    "# df_apple = load_or_save_df(\"apple\", 50) -- Didn't stop for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_costco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mcdonalds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samsung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating Features of Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compare (sentence) vectors\n",
    "# inputs v, w are vectors in list object forms\n",
    "# output can be between -1 and 1, where 1 means the best\n",
    "# for sentence vectors, output seems to be always between 0 and 1\n",
    "\n",
    "def cos_angle(v, w):\n",
    "    v = np.array(v)\n",
    "    w = np.array(w)\n",
    "    v = v.reshape(1,-1)\n",
    "    w = w.reshape(1,-1)\n",
    "    return cosine_similarity(v, w)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_feature(df, feature_query, feature_name):\n",
    "    vectors = df.Vectors\n",
    "    query_vector = get_sentence_embedding(feature_query)\n",
    "\n",
    "    cos_angles = map(lambda v: cos_angle(v, query_vector), vectors)\n",
    "    df[feature_name] = pd.DataFrame(cos_angles)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = insert_feature(df_costco, \"The quality was very good.\", \"Quality\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = insert_feature(df, \"The price is very reasonable.\", \"Price\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = insert_feature(df_costco, \"The quality was horrible.\", \"Quality (negative)\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = insert_feature(df, \"The price is exorbitant.\", \"Price (negative)\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Some Demonstrations of Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we consider Price vs. Price (negative) features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 price\n",
    "\n",
    "df.sort_values(by='Price', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom 5 price\n",
    "\n",
    "df.sort_values(by='Price', ascending = False).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 price (negative)\n",
    "\n",
    "df.sort_values(by='Price (negative)', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom 5 price (negative)\n",
    "\n",
    "df.sort_values(by='Price (negative)', ascending = False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we consider Quality vs. Quality (negative) features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Quality', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Quality', ascending = False).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Quality (negative)', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Quality (negative)', ascending = False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**. It does NOT seem that each feature and its negative version has high magnitute correlation (either positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Price','Price (negative)']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Quality','Quality (negative)']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**. From the pairplot below, it seems that negative questions may be better in creating features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
